{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:18.683941Z",
     "iopub.status.busy": "2024-11-14T22:05:18.682483Z",
     "iopub.status.idle": "2024-11-14T22:05:18.692279Z",
     "shell.execute_reply": "2024-11-14T22:05:18.691027Z",
     "shell.execute_reply.started": "2024-11-14T22:05:18.683887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:18.695675Z",
     "iopub.status.busy": "2024-11-14T22:05:18.695177Z",
     "iopub.status.idle": "2024-11-14T22:05:20.156501Z",
     "shell.execute_reply": "2024-11-14T22:05:20.155235Z",
     "shell.execute_reply.started": "2024-11-14T22:05:18.695619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Wczytuję wszytkie potrzebne narzędia doa obliczenai embeddingu jak i przeprowadzenia postprocessingu\n",
    "\n",
    "model = load_model(\"/kaggle/input/cnn_mel/keras/default/1/model.h5\");\n",
    "\n",
    "with open(\"/kaggle/input/tools-for-cross-validation-mel/scaler.pkl\", \"rb\") as file:\n",
    "    scaler_before_embedding = pickle.load(file)\n",
    "    \n",
    "with open(\"/kaggle/input/tools-for-cross-validation-mel/scaler_after_embedding.pkl\", \"rb\") as file:\n",
    "    scaler_after_embedding = pickle.load(file)\n",
    "\n",
    "with open(\"/kaggle/input/tools-for-cross-validation-mel/lda.pkl\", \"rb\") as file:\n",
    "    lda = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:20.158504Z",
     "iopub.status.busy": "2024-11-14T22:05:20.158054Z",
     "iopub.status.idle": "2024-11-14T22:05:20.171133Z",
     "shell.execute_reply": "2024-11-14T22:05:20.169801Z",
     "shell.execute_reply.started": "2024-11-14T22:05:20.158459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_audio_to_slices(path_to_files, seconds):\n",
    "    \n",
    "    # Przechodzę do katalogów wewnątrz folderu osoby (ID osoby).\n",
    "    # Każdy folder wewnętrzny zawiera więcej podfolderów, które mogą zawierać nagrania.\n",
    "    paths_inside_ID = [f.name for f in os.scandir(path_to_files) if f.is_dir()]\n",
    "\n",
    "    # Tworzę pełne ścieżki do podfolderów, aby przejść do wszystkich plików nagrań dla danej osoby.\n",
    "    full_paths_to_files = [path_to_files + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n",
    "\n",
    "    # Zbieram wszystkie ścieżki do plików audio danej osoby.\n",
    "    # Każdy plik powinien mieć rozszerzenie `.flac`, a wszystkie pliki są przechowywane w zmiennej `all_files_for_ID`.\n",
    "    \n",
    "    all_files_for_ID = []\n",
    "    for full_path_to_files in full_paths_to_files:\n",
    "        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n",
    "        files = [full_path_to_files + '/' + file for file in files]\n",
    "        all_files_for_ID = all_files_for_ID + files\n",
    "\n",
    "    # Łączę wszystkie nagrania danej osoby w jedno bardzo długie nagranie.\n",
    "    # Używam częstotliwości próbkowania 16kHz.\n",
    "    sr = 16000\n",
    "    combined_signals = np.array([])\n",
    "    for file_for_ID in all_files_for_ID:\n",
    "        signal, sr = librosa.load(file_for_ID, sr=sr)\n",
    "        combined_signals = np.concatenate([combined_signals, signal])\n",
    "\n",
    "    # Długie nagranie dzielę na  fragmenty o podanej długości.\n",
    "    # Fragmenty, które mają mniej niż zadeklarowane długości nagrania (resztki na końcu nagrania), są pomijane.\n",
    "    list_for_parts = []\n",
    "    len_of_combined_signals = len(combined_signals)\n",
    "    step = seconds * sr  # Ustawienie skoku na 5 sekund\n",
    "    for i in np.arange(start=0, stop=len_of_combined_signals-step, step=step):\n",
    "        list_for_parts.append(combined_signals[i:i+step].tolist())\n",
    "\n",
    "    \n",
    "    parts = np.array(list_for_parts)\n",
    "    \n",
    "    \n",
    "    # Funkcja zwraca pociętę na kawałki, o długości 1 sekundy nagrania\n",
    "    return parts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:20.174060Z",
     "iopub.status.busy": "2024-11-14T22:05:20.173499Z",
     "iopub.status.idle": "2024-11-14T22:05:20.193083Z",
     "shell.execute_reply": "2024-11-14T22:05:20.191566Z",
     "shell.execute_reply.started": "2024-11-14T22:05:20.174004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EbeddingExtractor:\n",
    "    \n",
    "    def __init__(self, model, scaler_before_embedding, scaler_after_embedding, lda):\n",
    "        self.model = model  # Przypisanie modelu do obiektu\n",
    "        self.lda = lda  # Przypisanie modelu LDA do obiektu\n",
    "        self.scaler_before_embedding = scaler_before_embedding  # Skaler do standaryzacji mel-spektorgramów przed generowaniem embeddingów\n",
    "        self.scaler_after_embedding = scaler_after_embedding  # Skaler do standaryzacji embeddingów przed zastosowaniem LDA\n",
    "\n",
    "    # Funkcja obliczająca mel-spektorgramy dla danego nagrania audio\n",
    "    def calucate_mel(self, audio):\n",
    "        quantity_of_mel_filters = 64\n",
    "\n",
    "        # Obliczanie mel-spektorgramów  za pomocą librosa\n",
    "        mel = librosa.feature.melspectrogram(y=audio, \n",
    "                                            sr=16000,  \n",
    "                                            n_mels=quantity_of_mel_filters).T\n",
    "        \n",
    "        # Standaryzacja mel-spektorgramów przed generowaniem embeddingów\n",
    "        mel = self.scaler_before_embedding.transform(mel)\n",
    "        return mel\n",
    "\n",
    "    # Funkcja obliczająca embedding na podstawie wcześniej przetworzonych mel-spektorgramów \n",
    "    def calcuate_embedding(self, audio_mel):\n",
    "        \n",
    "        intermediate_layer_model = Model(inputs=self.model.inputs,\n",
    "                                         outputs=self.model.get_layer('bottleneck').output)\n",
    "        intermediate_output = intermediate_layer_model.predict(audio_mel[np.newaxis, ...])\n",
    "        \n",
    "        return intermediate_output\n",
    "\n",
    "    # Funkcja postprocessingu embeddingu\n",
    "    def transform_audio_postprocessing(self, embedding):\n",
    "        embedding = self.scaler_after_embedding.transform(embedding)  # Standaryzacja embeddingu\n",
    "        embedding = self.lda.transform(embedding)  # Użycie LDA\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "# Tworzenie obiektu klasy EmbeddingExtractor z przekazaniem modelu, skalerów i modelu LDA\n",
    "EmbExtr = EbeddingExtractor(model=model, \n",
    "                            scaler_before_embedding=scaler_before_embedding,\n",
    "                            scaler_after_embedding=scaler_after_embedding,\n",
    "                            lda=lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:20.196961Z",
     "iopub.status.busy": "2024-11-14T22:05:20.196496Z",
     "iopub.status.idle": "2024-11-14T22:05:20.214558Z",
     "shell.execute_reply": "2024-11-14T22:05:20.213235Z",
     "shell.execute_reply.started": "2024-11-14T22:05:20.196915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/data-to-enrollment-and-test/data_to_cross_checking.pkl\", \"rb\") as file:\n",
    "    data_to_cross_checking = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T22:05:20.216617Z",
     "iopub.status.busy": "2024-11-14T22:05:20.216197Z",
     "iopub.status.idle": "2024-11-14T22:05:37.792354Z",
     "shell.execute_reply": "2024-11-14T22:05:37.790868Z",
     "shell.execute_reply.started": "2024-11-14T22:05:20.216554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_all_people = []  # Lista do przechowywania embeddingów dla wszystkich osób\n",
    "embedding_all_people_postprocessed = []\n",
    "# Pętla przetwarzająca nagrania dla każdej z 50 osób\n",
    "# Podana jest liczbaa 10 ponieważ zadanei podzieliłem na 5 kont kaggle\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    # Podział nagrania danej osoby na fragmenty 1-sekundowe za pomocą funkcji split_audio_to_slices\n",
    "    slices = split_audio_to_slices(data_to_cross_checking[i], seconds=1)\n",
    "    embedding_one_person = []  # Lista do przechowywania embeddingów dla pojedynczej osoby\n",
    "    embedding_one_person_postprocessed = []\n",
    "    \n",
    "    iterator = 0  # Inicjalizacja iteratora do śledzenia postępu przetwarzania\n",
    "    for slice in slices:\n",
    "        # Obliczanie mel-spektorgramów dla jednego fragmentu audio\n",
    "        mel = EmbExtr.calucate_mel(slice)\n",
    "        \n",
    "        # Generowanie embeddingu z obliczonych mel-spektorgramów \n",
    "        embedding = EmbExtr.calcuate_embedding(mel)\n",
    "        \n",
    "        # Postprocessing embeddingu - LDA\n",
    "        postprocessed_embedding = EmbExtr.transform_audio_postprocessing(embedding)\n",
    "        \n",
    "        # Dodanie przetworzonego embeddingu do listy embeddingów danej osoby\n",
    "        embedding_one_person_postprocessed.append(postprocessed_embedding)\n",
    "        embedding_one_person.append(embedding)\n",
    "        \n",
    "        # Aktualizacja iteratora i wyświetlanie postępu przetwarzania\n",
    "        iterator += 1\n",
    "        print(i + iterator / len(slices))  # Procentowy postęp przetwarzania dla osoby o ID i\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # Dodanie listy embeddingów danej osoby do głównej listy embeddingów dla wszystkich osób\n",
    "    embedding_all_people.append(embedding_one_person)\n",
    "    embedding_all_people_postprocessed.append(embedding_one_person_postprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-14T22:05:37.793321Z",
     "iopub.status.idle": "2024-11-14T22:05:37.793797Z",
     "shell.execute_reply": "2024-11-14T22:05:37.793594Z",
     "shell.execute_reply.started": "2024-11-14T22:05:37.793570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('embedding_all_people.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_all_people, file)\n",
    "\n",
    "with open('embedding_all_people_postprocessed.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_all_people_postprocessed, file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5923926,
     "sourceId": 9689961,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6010091,
     "sourceId": 9805327,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6088610,
     "sourceId": 9909511,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 163820,
     "modelInstanceId": 141198,
     "sourceId": 165940,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
